\documentclass[10pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{pstricks}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{fancyhdr}
\pagestyle{fancyplain}
\usepackage{lastpage}

\usepackage{multicol}
\usepackage{hyperref}







\theoremstyle{plain}
\newtheorem{theorem}{Theorem}\newtheorem*{theorem*}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{lemma*}{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\newtheoremstyle{box}%
{}{}% standard spacing before and after
{}% Body style
{}{\bfseries}{.}% Heading indent, font, and punctuation
{ }% space after heading
{\thmname{#1}\thmnumber{ #2}\thmnote{: #3}}% head spec


\theoremstyle{box}
\newtheorem{definition}{Definition}
\newtheorem*{definition*}{Definition}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem{question}{Question}
\newtheorem*{prep-problems}{Preparation Problems}

















\newcommand{\mytitle}{Jordan Form}
\newcommand{\myclass}{Math 341}

\rhead{pg. \thepage  \ of \pageref{LastPage}}    
\chead{\myclass}
\lhead{\mytitle}
\lfoot{\noindent(Draft \today)}
\cfoot{}



%The purpose of this code is to allow me to put lines in matrices so that I can create augmented matrices.
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

\newcommand{\ds}{\displaystyle}
\newcommand{\inv}{^{-1}}


\begin{document}


\noindent{\huge{\bf \mytitle}}

\noindent
This learning module covers the following ideas.  When you make your lesson plan, it should explain and contain examples of the following:
\begin{enumerate}

\item Solve differential equations related to investing.
\item Use eigenvalues and eigenvectors to solve systems of differential equations.
\item Use generalized eigenvectors to find Jordan canonical form.
\item Find the matrix exponential of a square matrix, and use it to solve linear homogeneous ODEs. 
\item Give applications of systems of ODEs, as they relate to dilution problems. 



\end{enumerate}


\section{Preparation and Suggested Homework}

Preparation Problems:
\begin{center}
\begin{tabular}{|l|llll|}\hline
Day 1& 1a, 2a, 2b, 3a,
\\\hline
Day 2& 3b, 4d, 4g, 4h, 5a, 5c
\\\hline
Day 3& 5e, 6a, 7a, 7b
\\\hline
\end{tabular}
\end{center}



The accompanying problems will serve as our problems set for this unit.  I will put up answers online as time permits.  You can use the technology introduction to check any answer, as well as give a step-by-step solution to any of the problems. However, on problems where the system is not diagonalizable, the matrix $Q$ used to obtain Jordan form is not unique (so your answer may differ a little, until you actually compute the matrix exponential $Qe^{Jt}Q^{-1}=e^{At}$).



\section{Differential Equations - Some introductory examples}
Problems in the real world often involving combining differential equations which interact with each other, resulting in a system of differential equations. Before embarking on a description of the solution techniques and real world applications, let's look at a few examples. In what follows, we will generally let $t$ be the independent variable, as $\vec x$ we'll use for talking about eigenvectors. 


\begin{example}
The equation $y^\prime = .05 y$ is called a differential equation because it contains a function $y$ and its derivative $y^\prime$.  This equation models the growth of an investment which is gaining 5\% interest, compounded continuously.  The rate at which money is accumulated ($y^\prime(t)$) is equal to the amount of money in the account ($y(t)$) times the interest rate.  You may recall the formula $I=Pr$ (interest = principal times intereset rate).  
To solve the differential equation $y^\prime = .05 y$, we need to find the function $y$ which satisfies this differential equation.  If we write $\frac{dy}{dt} = .05 y$ and multiply both sides by $dt$ and divide both sides by $y$, we obtain the equation $\frac{1}{y}dy=.05 dt$. Integrating both sides gives us the equation $\ln|y|=.05 t +c$ for some constant $c$. Exponentiate both sides to obtain $y=e^{.05 t+c} = e^{.05t}e^c$.  If we note that $e^c$ is just another constant, we can then write $y=e^{.05 t}c$.  We can verify that our solution is correct by taking the derivative and obtain $y^\prime = .05 e^{.05 t}c = .05 y$, which is our differential equation.

If we had 1000 dollars to start with at time $t=0$, then we can use the initial value $y(0)=1000$ in our general solution to obtain a value for $c$ by writing $1000 = c e^0=c$. With this initial condition, the solution to our differential equation is precisely $y = e^{.05 t} 1000$. Some of you may recall the interest formula $A=Pe^{rt}$, where $P$ is the initial investment, $r$ is the interest rate, $t$ is the time, and $A$ is the amount of money in your account. This general formula can be obtained using the exact same steps used above.
\end{example}

In the last example, we began with a differential equation and solved for the function $y$ which satisfies this differential equation. The differential equation $y^\prime - a y=0$ provides us with a fundamental tool for solving differential equations in all dimensions.  The solution to this differential equation is $y = e^{at}c$ for some constant $c$. In terms of linear algebra, a basis for the solution is $\{e^{at}\}$, as all other solutions are linear combinations of this solution.  We will now explore what happens if we try to solve multiple ODE simultaneously. The solution will involve finding eigenvalues, eigenvectors, and diagonalizing a matrix.  The key reason for this unit is to learn why diagonalizing a matrix is so useful.

Consider the system of ODE's $y_1^\prime(t)=2y_1(t)+y_2(t)$ and $y_2^\prime(t) = y_1(t)+2y_2(t)$.  This system can be written in matrix form as 
$
\begin{bmatrix}y_1^\prime\\y_2^\prime\end{bmatrix} 
= 
\begin{bmatrix}2&1\\1&2\end{bmatrix} 
\begin{bmatrix}y_1\\y_2\end{bmatrix}
$. 
We can summarize this in vector and matrix form by writing $\vec y^\prime =A\vec y$. 
Since the system of ODEs $\vec y^\prime =A\vec y$ is similar to the ODE $y^\prime=Ay$ whose solution involves an exponential function, we can guess that a solution to $\vec y^\prime =A\vec y$ will be of the form $\begin{bmatrix}x_1\\x_2\end{bmatrix}e^{\lambda t}$ for some constant vector $\vec x=\begin{bmatrix}x_1\\x_2\end{bmatrix}$ and constant $\lambda$.  
Differentiating and substituting into the ODE gives $\lambda \vec x e^{\lambda t}=A\vec x e^{\lambda t} $, or $\lambda \vec x =A\vec x $. In other words, we need a scalar $\lambda$ and a vector $\vec x$ such that multiplying $\vec x$ on the left by a matrix $A$ is equivalent to multiplying by a constant $\lambda$.  \textbf{This is an eigenvalue and eigenvector problem}. The matrix 
$A=\begin{bmatrix}2&1\\1&2\end{bmatrix}$ has eigenvalues $\lambda_1 = 1$ and $\lambda_2= 3$, with corresponding eigenvectors $\vec x_1=\begin{bmatrix}1\\-1\end{bmatrix}$ and $\vec x_2=\begin{bmatrix}1\\1\end{bmatrix}$ (check this is true). Hence, two solutions to the system of ODE's are 
$ \begin{bmatrix}y_1\\y_2\end{bmatrix} = \begin{bmatrix}1\\-1\end{bmatrix}e^t$ and 
$ \begin{bmatrix}y_1\\y_2\end{bmatrix} = \begin{bmatrix}1\\1\end{bmatrix}e^{3t}$. These two solutions form a basis of solutions. All other solutions are linear combinations of these two solutions. The general solution to this system of differential equations is hence $ \begin{bmatrix}y_1\\y_2\end{bmatrix} 
= c_1\begin{bmatrix}1\\-1\end{bmatrix}e^t 
+ c_2\begin{bmatrix}1\\1\end{bmatrix}e^{3t}
=
\begin{bmatrix}c_1e^t + c_2e^{3t}\\-c_1e^t + c_2e^{3t}\end{bmatrix}$. 

\subsection{The Eigenvalue approach to Solving Linear Systems of ODEs}

We will consider linear systems of differential equations which can be written in the form $\vec y^\prime = A\vec y$, where $A$ is a matrix with constants.  Following the key examples above, we can guess that a solution is of the form $\vec xe^{\lambda t}$ for some $\lambda$ and vector $\vec x$. Hence we have $\lambda \vec x e^{\lambda t}=A\vec x e^\lambda t $, or $\lambda \vec x =A\vec x $, which is an eigenvalue problem. We find that $\vec x e^{\lambda t}$ is a solution of the systems of ODEs for any eigenvalue $\lambda$ with a corresponding eigenvector $\vec x$. This is the general theory.  In particular, if the eigenvalues are $\lambda_1,\ldots,\lambda_n$ (whether there are repeats or not), and there are $n$ linearly independent eigenvectors $\vec x_{i}$, then the general solution is $\vec y = c_1\vec x_{1} e^{\lambda_1 t} + \cdots + c_n\vec x_{n} e^{\lambda_n t}$. 

\begin{example}
Consider the system of ODEs $y_1^\prime = 2y_1+y_2, y_2^\prime= y_1+2y_2$ from the key example, but add in the initial conditions $y_1(0)=3,y_2(0)=4$. Since the eigenvalues are 1 and 3 with eigenvectors $[1,-1],[1,1]$, the general solution is 
$
\begin{bmatrix}y_1\\y_2\end{bmatrix} 
= c_1\begin{bmatrix}1\\-1\end{bmatrix}e^t 
+ c_2\begin{bmatrix}1\\1\end{bmatrix}e^{3t}
=
\begin{bmatrix}1 &1\\-1&1\end{bmatrix}
\begin{bmatrix}e^t&0\\0&e^{3t}\end{bmatrix}
\begin{bmatrix}c_1\\c_2\end{bmatrix} 
$. 
The initial conditions give us the matrix equation 
$
\begin{bmatrix}3\\4\end{bmatrix} 
= 
\begin{bmatrix}1 &1\\-1&1\end{bmatrix}
\begin{bmatrix}1&0\\0&1\end{bmatrix}
\begin{bmatrix}c_1\\c_2\end{bmatrix} 
=
\begin{bmatrix}1 &1\\-1&1\end{bmatrix}
\begin{bmatrix}c_1\\c_2\end{bmatrix} 
$, which can be solved using Cramer's rule (which we have done for much of the semester) or by using an inverse matrix.  If we let $Q = \begin{bmatrix}1 &1\\-1&1\end{bmatrix}$, then the constants $c_1$ and $c_2$ are found by writing $\vec c = Q^{-1} \vec y(0)$, or 
$$
\begin{bmatrix}c_1\\c_2\end{bmatrix} 
=
\begin{bmatrix}1 &1\\-1&1\end{bmatrix}^{-1}
\begin{bmatrix}3\\4\end{bmatrix} 
=
\frac{1}{2}
\begin{bmatrix}1 &-1\\1&1\end{bmatrix}
\begin{bmatrix}3\\4\end{bmatrix} 
=
\frac{1}{2}
\begin{bmatrix}-1 \\7\end{bmatrix}
,$$ or $c_1=-\frac12, c_2=\frac72$.  Hence the solution to our IVP is 
$ \begin{bmatrix}y_1\\y_2\end{bmatrix} 
= -\frac12\begin{bmatrix}1\\-1\end{bmatrix}e^t 
+ \frac72\begin{bmatrix}1\\1\end{bmatrix}e^{3t}
=
\begin{bmatrix}-\frac12e^t + \frac72e^{3t}\\\frac12e^t + \frac72e^{3t}\end{bmatrix}$.
\end{example}

In the previous example, we used the inverse matrix to find our constants from our initial conditions.  Notice that the general solution was written in the form $\vec y = QD\vec c$ where $Q$ is a matrix whose columns are the eigenvectors of $A$, and $D$ is a diagonal matrix with $e^{\lambda t}$ on the diagonals for our eigenvalues $\lambda$.  We then wrote $\vec c = Q^{-1}\vec y(0)$, which means we could write our solution in the form 
$\vec y = QDQ^{-1}\vec y(0)$. The matrix $QDQ^{-1}$ is called the matrix exponential of $At$, and we will soon show that it equals $e^{At}$, where we place a matrix in the exponent of $e$. If we are given initial conditions, then we can find a solution to our system of differential equations $\vec y^\prime = A\vec y$ by using the following 4 step process: 
\begin{enumerate}
	\item Find the eigenvalues of $A$ to create $D$ (put $e^{\lambda t}$ on the diagonals).
	\item Find the eigenvectors to create $Q$ (put your eigenvectors in the columns).
	\item Find the inverse of $Q$ (quick for 2 by 2 matrices, use a computer for anything larger).
	\item Compute the product $\vec y = QDQ^{-1}\vec y(0) = e^{At}\vec y(0)$ and you're done. 
\end{enumerate}
This will solve every linear homogeneous differential equation, provided the eigenvalues are distinct and real. The rest of this document deals with what to do in the case of a double root, where $n$ linearly independent eigenvectors are not obtainable. 



\section{Jordan Canonical Form}
The matrix $\begin{bmatrix} 2&1\\1&2\end{bmatrix} $ has eigenvalues $\lambda=1,3$ and eigenvectors $\begin{bmatrix} -1\\1\end{bmatrix} $, $\begin{bmatrix} 1\\1\end{bmatrix} $ (check this). Let $Q = \begin {bmatrix} -1&1\\1&1\end {bmatrix} $ be a matrix whose columns are linearly independent eigenvectors of $A$.  Then the product $Q^{-1}AQ = \begin {bmatrix} 1&0\\0&3\end {bmatrix}$ is a diagonal matrix whose entries are the eigenvalues of $A$ (written in the same order in which the eigenvectors were listed in $Q$.  This process (finding $Q$ and multiplying $J=Q^{-1}AQ$) is called diagonalizing a matrix, and is always possible for an $n\times n$ matrix which has $n$ linearly independent eigenvectors. Notationally we often write $Q^{-1}AQ=J$ for the diagonal matrix $J$, and $J$ is called a Jordan canonical form for $A$.  

\begin{wraptable}{r}{0pt}
$\begin{bmatrix}
2&1&0&0\\
0&2&1&0\\
0&0&2&0\\
0&0&0&3\\
\end{bmatrix}$
\end{wraptable}
If $A$ has an eigenvalue $\lambda$ which occurs $k$ times (we say its algebraic multiplicity is $k$), but does not have $k$ linearly independent eigenvectors (the geometric multiplicity is less than $k$), then we call the eigenvalue defective. In this case, it is impossible to diagonalize $A$. However, it is possible to find a matrix $J$ whose diagonal entries are the eigenvalues and the only nonzero terms are a few 1's which are found directly above the defective eigenvalues. The matrix on the right 
 is a Jordan canonical form for a matrix whose eigenvalues are $2,2,2,$ and $3$ where $2$ is a defective eigenvalue. To find this matrix $J$, we need to find generalized eigenvectors, which are vectors that satisfy $(A-\lambda I)^r\vec x=\vec 0$ for some $r$.  If $\vec x$ is a vector which satisfies this equation for $r$ but not for $r-1$, then we call $r$ the rank of the eigenvector $\vec x$. We will focus our examples on $2\times 2$ and $3\times 3$ matrices. It can be shown that if the algebraic multiplicity of an eigenvector is $k$, then there will be $k$ linearly independent generalized eigenvalues, which we can then use to obtain the Jordan form.

This paragraph explains a method for finding generalized eigenvectors.  The examples which follow illustrate this idea. Skim read this paragraph, try the examples, and then come back and read it again. A generalized eigenvector $\vec v_r$ of rank $r$ satisfies $(A-\lambda I)^r\vec v_r=\vec 0$ but not $(A-\lambda I)^{r-1}\vec v_r=\vec 0$.  If we let $\vec v_{r-1}= (A-\lambda I)\vec v_r$, then $\vec v_{r-1}$ is a generalized eigenvector of rank $r-1$. The equation $\vec v_{r-1}=(A-\lambda I)^r\vec v_r$ gives us a way of solving for $\vec v_{r}$ based upon $\vec v_{r-1}$. Similarly, we could use $\vec v_{r-2}$ to obtain $\vec v_{r-1}$.   If we repeat this process until we get back to $\vec v_1$ (which is an actual eigenvector), then we can write all of the generalized eigenvectors in terms of a basis of eigenvectors. If $\vec v_1$ is an eigenvector, then we solve $(A-\lambda I)\vec v_2 =\vec v_1$ to find $\vec v_2$. We then solve  $(A-\lambda I)\vec v_3 =\vec v_2$ to find $\vec v_3$. Continue this process to obtain a chain of generalized eigenvectors $\vec v_1, \vec v_2, \ldots, \vec v_r$ which are then inserted in the matrix $Q$ to obtain Jordan form.

\begin{example}
Let $A=\begin {bmatrix} 0&1\\-1&-2\end {bmatrix}$. The characteristic polynomial is $\begin {vmatrix} -\lambda&1\\-1&-2-\lambda\end {vmatrix}= \lambda^2+2\lambda+1=(\lambda+1)^2$. A double eigenvalue is $\lambda=-1$.  To find the eigenvectors we compute {$A-\lambda I = \begin {bmatrix} 1&1\\-1&-1\end {bmatrix} $}. The only eigenvectors are multiples of $\vec v_1 = \begin {bmatrix} 1\\-1\end {bmatrix}$. Hence there is only one linearly independent eigenvector for the double root $-1$, which means $-1$ is a defective eigenvalue. In order to find Jordan Form, we must find a generalized eigenvector of rank 2. 

We solve the equation 
$(A-\lambda I)\vec v_2=\vec v_1$ by row reducing the matrix 
$\begin {bmatrix}[cc|c] 1&1&1\\-1&-1&-1\end {bmatrix}$, which gives the solution $x_1+x_2=1$ (notice we just augmented $A-\lambda I$ by our eigenvector).  The vectors $[1,0]$ and $[0,1]$ both satisfy this system, so we can pick either vector as $\vec v_2$ (it doesn't matter which one you pick). Now let $Q=\begin{bmatrix}\vec v_1 &\vec v_2\end{bmatrix}$. The Jordan form is then $Q^{-1}AQ = =\begin {bmatrix} -1&1\\0&-1\end {bmatrix}$.  
\end{example}

The example above gives a general method for finding Jordan form. Start by finding the eigenvalues. For each eigenvalue, find a basis of eigenvectors.  For each eigenvector in this basis, use the equation $\vec v_{k-1}=(A-\lambda I)^r\vec v_k$ to obtain a chain of generalized eigenvectors $\{\vec v_1,\vec v_2, \ldots, \vec v_r\}$ corresponding to that eigenvector (the chain stops when the equation $\vec v_{k-1}=(A-\lambda I)^r\vec v_k$ has no solution, which will always occur). Once you have completed this, you will find that the total number of generalized eigenvectors you have obtained matches the size of the matrix, and that the vectors are linearly independent (proving this is not difficult, but beyond the scope of our class). Place the vectors into the columns of $Q$ (keeping the chains together) and then the product $Q^{-1}AQ=J$ will give you a Jordan form, where each chain of vectors corresponds to a block matrix on the diagonal whose diagonal entries are the eigenvalue and 1's above the main diagonal.

\begin{example}
Consider the matrix 
$A=
\begin{bmatrix}
4&-4&10\\
1&0&5\\
0&0&2
\end{bmatrix}
$. The characteristic polynomial is $-\lambda^3+6\lambda^2-12 t+8 = (2-\lambda)^3$, so $A$ has one eigenvalue, namely $\lambda=2$.  We compute $A-2I = \begin{bmatrix} 2&-4&10\\1&-2&5
\\0&0&0\end{bmatrix} 
$.  Row reduction gives $\begin{bmatrix} 1&-2&5\\0&0&0
\\0&0&0\end{bmatrix} 
$, so two linearly independent eigenvectors are $\begin{bmatrix}2\\1\\0\end{bmatrix}$   and $\begin{bmatrix}-5\\0\\1\end{bmatrix}$.  We currently have only 2 linearly independent vectors, so we have to find a third.  We solve $(A-2I)v_2= \begin{bmatrix}2\\1\\0\end{bmatrix}$ by row reducing $ \begin{bmatrix} 2&-4&10&2\\1&-2&5&1
\\0&0&0&0\end{bmatrix} 
$ to obtain $\begin{bmatrix} 1&-2&5&1\\0&0&0&0
\\0&0&0&0\end{bmatrix}$, which means $\vec v_2=\begin{bmatrix}1\\0\\0\end{bmatrix}$ is a generalized eigenvector since $1-2(0)+5(0)=1$. We now have three independent vectors, so we can use them to form the matrix $Q$.
We have $Q= \begin{bmatrix} 2&1&-5\\1&0&0
\\0&0&1\end{bmatrix}$.  The inverse of $Q$ is 
$\begin{bmatrix} 0&1&0\\1&-2&5
\\0&0&1\end{bmatrix}
$ (using a computer). Matrix multiplication gives $Q^{-1}AQ = \begin{bmatrix} 2&1&0\\0&2&0
\\0&0&2\end{bmatrix}
$ as the Jordan Form.

As a side note, if we try to find any more generalized eigenvectors, we will fail because we will get inconsistent systems. Reduction of the matrix 
$ \begin{bmatrix} 2&-4&10&1\\1&-2&5&0
\\0&0&0&0\end{bmatrix} 
$ gives $\begin{bmatrix} 1&-2&5&0\\0&0&0&1
\\0&0&0&0\end{bmatrix}$ which means there is no rank 3 eigenvector in the first chain. Row reduction of the matrix 
$ \begin{bmatrix} 2&-4&10&-5\\1&-2&5&0
\\0&0&0&1\end{bmatrix} 
$ gives $\begin{bmatrix} 1&-2&5&0\\0&0&0&1
\\0&0&0&0\end{bmatrix}$ which has no solution, meaning that the second chain is only one long, and there are no generalized eigenvectors of rank 2 for the second eigenvector.  
\end{example}

\begin{example}
Consider the matrix 
$ \begin{bmatrix} 
1&2&2\\
0&1&0\\
0&0&1
\end{bmatrix} 
$.  Because it is upper triangular, the eigenvalues are the entries on the diagonal, namely $\lambda = 1$ is an eigenvalue with algebraic multiplicity 3. To find the eigenvectors, we note that the matrix 
$A-I= \begin{bmatrix} 
0&2&2\\
0&0&0\\
0&0&0
\end{bmatrix} 
$
has only 1 pivot, so it has 2 free variable, or two linearly independent eigenvectors 
$\begin{bmatrix} 
1\\
0\\
0
\end{bmatrix}$ 
and
$\begin{bmatrix} 
0\\
1\\
-1
\end{bmatrix}$. 
Since there are only 2 linearly independent eigenvectors, we need to find a third.  Row reduction of $\begin{bmatrix} 
0&2&2&1\\
0&0&0&0\\
0&0&0&0
\end{bmatrix}$ 
shows that  
$\begin{bmatrix} 
0\\
1/2\\
0
\end{bmatrix}$ is a generalized eigenvector.  Hence we let $Q=\begin{bmatrix} 
1&0&0\\
0&1/2&1\\
0&0&-1
\end{bmatrix} 
$ and then compute $Q^{-1} = \begin{bmatrix} 
1&0&0\\
0&2&2\\
0&0&-1
\end{bmatrix} 
$. 
Then a Jordan Canonical form is $J=Q^{-1}AQ=\begin{bmatrix} 
1&1&0\\
0&1&0\\
0&0&1
\end{bmatrix} 
$. 

\end{example}





\begin{example}
Consider the matrix 
$ A=\begin{bmatrix} 
1&2&2\\
0&1&2\\
0&0&1
\end{bmatrix} 
$.  Because it is upper triangular, $\lambda = 1$ is a triple eigenvalue. To find the eigenvectors, we note that the matrix 
$A-I= \begin{bmatrix} 
0&2&2\\
0&0&2\\
0&0&0
\end{bmatrix} 
$
has 2 pivots, so one linearly independent eigenvector 
$\begin{bmatrix} 
1\\
0\\
0
\end{bmatrix}$. 
Since there is only one linearly independent eigenvector, we need to find two linearly independent generalized eigenvectors. Row reduction of $\begin{bmatrix} 
0&2&2&1\\
0&0&2&0\\
0&0&0&0
\end{bmatrix}$ 
shows that  
$\begin{bmatrix} 
0\\
1/2\\
0
\end{bmatrix}$ is a rank 2 generalized eigenvector. Replacing the 4th column of the previous calculation with this rank 2 eigenvector gives us the matrix 
$\begin{bmatrix} 
0&2&2&0\\
0&0&2&1/2\\
0&0&0&0
\end{bmatrix}$, which shows that $\begin{bmatrix} 
0\\
-1/4\\
1/4
\end{bmatrix}$ is a rank 3 generalized eigenvector (just reduce the matrix to discover this).
Let $Q=\begin{bmatrix} 
1&0&0\\
0&1/2&-1/4\\
0&0&1/4
\end{bmatrix} 
$ and then compute $Q^{-1} = \begin{bmatrix} 
1&0&0\\
0&2&2\\
0&0&4
\end{bmatrix} 
$. 
Jordan Canonical form is $J=Q^{-1}AQ=\begin{bmatrix} 
1&1&0\\
0&1&1\\
0&0&1
\end{bmatrix} 
$. 



\end{example}












\section{The Matrix Exponential}
What we are about to learn in this unit is a very powerful tool which essentially encompasses and explains almost every idea in an introductory ODE class.   Recall that the solution to the differential equation $y^\prime = ay$ is $y=e^{at}c$. To solve this in higher dimensions, the solution is simply $\vec y=e^{At}\vec c$.  The key thing we need to learn before we can proceed any more is to understand what the matrix exponential $e^{At}$ means. When a matrix is diagonalizable $D=Q^{-1} A Q$, then the matrix exponential is precisely $Qe^{D}Q^{-1}=e^{A}$ (which is why the eigenvalue approach to solving differential equations worked).

For those of you who have had math 113, recall that the MacLaurin series of $e^x$ is
$$e^x = \sum_{n=0}^\infty \frac{1}{n!}x^n = 1+x+\frac{1}{2!}x^2+\frac{1}{3!}x^3+\frac{1}{4!}x^4+\cdots.$$
We now introduce the exponential of a matrix $A$ by using the exact same idea, namely we define $e^A$ as the infinite series
$$e^A = exp(A) = \sum_{n=0}^\infty \frac{1}{n!}A^n = 1+x+\frac{1}{2!}A^2+\frac{1}{3!}A^3+\frac{1}{4!}A^4+\cdots.$$
We will use the following facts without proof.
\begin{enumerate}
	\item The matrix exponential exists for every square matrix. In other words, the infinite sum will always converge.
	\item The inverse of the matrix exponential of $A$ is the matrix exponential of $-A$, i.e. $(e^A)^{-1}=e^{-A}$. 
	\item If two matrices commute (meaning $AB=BA$), then  $e^{A+B}=e^Ae^B = e^Be^A$.
\end{enumerate}
Essentially, these facts mean that the laws of exponents with numbers are the same as the laws of exponents with matrices.


\subsection{The Matrix Exponential for Diagonal Matrices - exponentiate the diagonals}
We'll start by computing the matrix exponential for a few diagonal matrices.  Let's start with the zero matrix
$A=
\begin{bmatrix}
 0 & 0 \\
 0 & 0
	\end{bmatrix}
$. 
 Every power of $A$ is the zero matrix, expect the zeroth power which is the identity matrix.  Hence we have
$$e^A = 
\begin{bmatrix}
 1 & 0 \\
 0 & 1
	\end{bmatrix}
+
\begin{bmatrix}
 0 & 0 \\
 0 & 0
	\end{bmatrix}
+\cdots = 
\begin{bmatrix}
 1 & 0 \\
 0 & 1
	\end{bmatrix}
.$$
This shows us that $e^{0} = I$, the identity matrix.

Now let's compute the exponential of the identity matrix, $A=
\begin{bmatrix}
 1 & 0 \\
 0 & 1
\end{bmatrix}
$
Every power will still be I, so we have 
$$e^A = 
\begin{bmatrix}
 1 & 0 \\
 0 & 1
\end{bmatrix}
+
\begin{bmatrix}
 1 & 0 \\
 0 & 1
\end{bmatrix}
+
\begin{bmatrix}
 \frac{1}{2!} & 0 \\
 0 & \frac{1}{2!}
\end{bmatrix}
+
\begin{bmatrix}
 \frac{1}{3!} & 0 \\
 0 & \frac{1}{3!}
\end{bmatrix}
+\cdots = 
\begin{bmatrix}
 1+1+\frac{1}{2!}+\frac{1}{3!}+\cdots & 0 \\
 0 & 1+1+\frac{1}{2!}+\frac{1}{3!}+\cdots
\end{bmatrix}
.$$
In summary, we have $e^I = 
\begin{bmatrix}
 e^1 & 0 \\
 0 & e^1
\end{bmatrix}
$. For the diagonal matrix 
$A=
\begin{bmatrix}
 a & 0 \\
 0 & b
\end{bmatrix}
$, a similar computation shows that $e^{A} = 
\begin{bmatrix}
 e^a & 0 \\
 0 & e^b
\end{bmatrix}
.$  If we multiply $A$ by $t$ and then exponentiate, we obtain 
$e^(At) = 
\begin{bmatrix}
 e^{at} & 0 \\
 0 & e^{bt}
\end{bmatrix}
.$ 
The ideas above generalize immediately to all $n\times n$ matrices. If $A$ is a diagonal matrix, then its matrix exponential is found by exponentiating all the terms on the diagonal.  



\subsection{Nilpotent Matrices - Matrices where $A^n=0$ for some $n$}
A nilpotent matrix is a matrix for which $A^n=0$ for some $n$. This means that the infinite sum involved in the matrix exponential eventually terminates. We will only look at a few examples of nilpotent matrices, in particular the kinds that show up when calculating Jordan form. 

The matrix $A=
\begin{bmatrix}
 0 & t \\
 0 & 0
\end{bmatrix}
$ is nilpotent because 
$
\begin{bmatrix}
 0 & t \\
 0 & 0
\end{bmatrix}
^2
=
\begin{bmatrix}
 0 & 0 \\
 0 & 0
\end{bmatrix}
$. 
The matrix exponential is hence 
$$e^A = 
\begin{bmatrix}
 1 & 0 \\
 0 & 1
\end{bmatrix}
+
\begin{bmatrix}
 0 & t \\
 0 & 0
\end{bmatrix}
+
\begin{bmatrix}
 0 & 0 \\
 0 & 0
\end{bmatrix}
=
\begin{bmatrix}
 1 & t \\
 0 & 1
\end{bmatrix}
.
$$

The matrix $A=
\begin{bmatrix}
 0 & t & 0 \\
 0 & 0 & t \\
 0 & 0 & 0
\end{bmatrix}
$ satisfies $A^2 = 
\begin{bmatrix}
 0 & 0 & t^2 \\
 0 & 0 & 0 \\
 0 & 0 & 0
\end{bmatrix}
$ and
$A^3 = 
\begin{bmatrix}
 0 & 0 & 0 \\
 0 & 0 & 0 \\
 0 & 0 & 0
\end{bmatrix}
$, hence it is nilpotent. Its matrix exponential is
$e^A=
\begin{bmatrix}
 1 & 0 & 0 \\
 0 & 1 & 0 \\
 0 & 0 & 1
\end{bmatrix}
+
\begin{bmatrix}
 0 & t & 0 \\
 0 & 0 & t \\
 0 & 0 & 0
\end{bmatrix}
+\frac{1}{2}
\begin{bmatrix}
 0 & 0 & t^2 \\
 0 & 0 & 0 \\
 0 & 0 & 0
\end{bmatrix}
=
\begin{bmatrix}
 1 & t & \frac{1}{2}t^2 \\
 0 & 1 & t \\
 0 & 0 & 1
\end{bmatrix}
$


The 4 by 4 matrix $A=
\begin{bmatrix}
 0 & t & 0 & 0 \\
 0 & 0 & t & 0 \\
 0 & 0 & 0 & t \\
 0 & 0 & 0 & 0
\end{bmatrix}
$ satisfies
$A^2 = 
\begin{bmatrix}
 0 & 0 & t^2 & 0 \\
 0 & 0 & 0 & t^2 \\
 0 & 0 & 0 & 0 \\
 0 & 0 & 0 & 0
\end{bmatrix}
,
A^2 = 
\begin{bmatrix}
 0 & 0 & 0 & t^3 \\
 0 & 0 & 0 & 0 \\
 0 & 0 & 0 & 0 \\
 0 & 0 & 0 & 0
\end{bmatrix}
,$ and
$A^4 = 0,$ so it is nilpotent. Its matrix exponential is
$
\begin{bmatrix}
 1 & t & \frac{1}{2!}t^2 & \frac{1}{3!}t^3 \\
 0 & 1 & t & \frac{1}{2!}t^2 \\
 0 & 0 & 1 & t \\
 0 & 0 & 0 & 1
\end{bmatrix}
$. 

The point to these last few examples is to help you see a pattern. If there are not all $t$'s on the upper diagonal, then each block of $t$'s will contribute a similar matrix.  For example, the exponential of the matrix 
$
\begin{bmatrix}[ccc|cccc]
 0 & t & 0 & 0 & 0 & 0 & 0 \\
 0 & 0 & t & 0 & 0 & 0 & 0 \\
 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\hline
 0 & 0 & 0 & 0 & t & 0 & 0 \\
 0 & 0 & 0 & 0 & 0 & t & 0 \\
 0 & 0 & 0 & 0 & 0 & 0 & t \\
 0 & 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}
$ is
$
\begin{bmatrix}[ccc|cccc]
 1 & t & \frac{1}{2}t^2 & 0 & 0 & 0 & 0 \\
 0 & 1 & t & 0 & 0 & 0 & 0 \\
 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\hline
 0 & 0 & 0 & 1 & t & \frac{1}{2}t^2 & \frac{1}{3!}t^3 \\
 0 & 0 & 0 & 0 & 1 & t & \frac{1}{2}t^2 \\
 0 & 0 & 0 & 0 & 0 & 1 & t \\
 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
$

\subsection{Matrices in Jordan Form}
If a matrix is in Jordan form, then it can be written as $J=D+N$, where $D$ is a diagonal matrix and $N$ is a nilpotent matrix similar to the matrices from the last section. Since $e^{D+N}=e^De^N$, all we have to do is multiply the two matrix exponential together to find the matrix exponential of $J$. We will almost always be working with matrices of the form $Jt$, so we need the matrix exponential of $Dt$ and $Nt$.  Let's look at an example.

Consider the matrix $J=
\begin{bmatrix}
 2 & 1 \\
 0 & 2
\end{bmatrix}
$, which is already in Jordan form.  We write $Jt=Dt+Nt$ as
$
\begin{bmatrix}
 2t & t \\
 0 & 2t
\end{bmatrix}
=
\begin{bmatrix}
 2t & 0 \\
 0 & 2t
\end{bmatrix}
+
\begin{bmatrix}
 0 & t \\
 0 & 0
\end{bmatrix}
$.  The matrix exponentials are $e^{Dt}= 
\begin{bmatrix}
 e^{2t} & 0 \\
 0 & e^{2t}
\end{bmatrix}
$ and $e^{Nt} = 
\begin{bmatrix}
 1 & t \\
 0 & 1
\end{bmatrix}
$. The product of these two matrices is the matrix exponential of $Jt$, namely $e^{Jt} = 
\begin{bmatrix}
 e^{2 t} & e^{2 t} t \\
 0 & e^{2 t}
\end{bmatrix}
$.  Similar computations shows that the matrix exponential of 
$
\begin{bmatrix}
 2 t & t & 0 \\
 0 & 2 t & t \\
 0 & 0 & 2 t
\end{bmatrix}
$ is 
$
\begin{bmatrix}
 e^{2 t} & e^{2 t} t & \frac{1}{2} e^{2 t} t^2 \\
 0 & e^{2 t} & e^{2 t} t \\
 0 & 0 & e^{2 t}
\end{bmatrix}
$, and the matrix exponential of 
$
\begin{bmatrix}
 2 t & t & 0 & 0 \\
 0 & 2 t & t & 0 \\
 0 & 0 & 2 t & t \\
 0 & 0 & 0 & 2 t
\end{bmatrix}
$ is $
\begin{bmatrix}
 e^{2 t} & e^{2 t} t & \frac{1}{2} e^{2 t} t^2 & \frac{1}{3!} e^{2 t} t^3
   \\
 0 & e^{2 t} & e^{2 t} t & \frac{1}{2} e^{2 t} t^2 \\
 0 & 0 & e^{2 t} & e^{2 t} t \\
 0 & 0 & 0 & e^{2 t}
\end{bmatrix}
$.  The pattern that you see continues. If you change the eigenvalues on the diagonal, then the 2 in the exponent will change.  If there are multiple eigenvalues, then each block of eigenvalues will contribute a block matrix to the matrix exponential. For a large example, we compute 
$$exp 
\begin{bmatrix}[ccc|cccc]
 3 t & t & 0 & 0 & 0 & 0 & 0 \\
 0 & 3 t & t & 0 & 0 & 0 & 0 \\
 0 & 0 & 3 t & 0 & 0 & 0 & 0 \\\hline
 0 & 0 & 0 & 2 t & t & 0 & 0 \\
 0 & 0 & 0 & 0 & 2 t & t & 0 \\
 0 & 0 & 0 & 0 & 0 & 2 t & t \\
 0 & 0 & 0 & 0 & 0 & 0 & 2 t
\end{bmatrix}
=
\begin{bmatrix}[ccc|cccc]
 e^{3 t} & e^{3 t} t & \frac{1}{2} e^{3 t} t^2 & 0 & 0 & 0 & 0 \\
 0 & e^{3 t} & e^{3 t} t & 0 & 0 & 0 & 0 \\
 0 & 0 & e^{3 t} & 0 & 0 & 0 & 0 \\ \hline
 0 & 0 & 0 & e^{2 t} & e^{2 t} t & \frac{1}{2} e^{2 t} t^2 & \frac{1}{3!} e^{2 t} t^3 \\
 0 & 0 & 0 & 0 & e^{2 t} & e^{2 t} t & \frac{1}{2} e^{2 t} t^2 \\
 0 & 0 & 0 & 0 & 0 & e^{2 t} & e^{2 t} t \\
 0 & 0 & 0 & 0 & 0 & 0 & e^{2 t}
\end{bmatrix}
.$$





\subsection{Jordan form gives the matrix exponential for any matrix.}

We now consider the matrix exponential of any matrix $A$.  Start by finding $Q$ and $J$ so that $Q^{-1}AQ=J$ is a Jordan form for $A$.  This means that $A=Q J Q^{-1}$.  Notice that 
$A^2 = Q J Q^{-1}Q J Q^{-1} = Q J^2 Q^{-1}$, 
$A^3 = Q J Q^{-1}Q J Q^{-1}Q J Q^{-1} = Q J^3 Q^{-1}$, and 
$A^n = Q J^n Q^{-1}$.  This means that the matrix exponential of $A$ is 
$$e^A = \sum_{n=0}^\infty \frac{1}{n!}A^n = \sum_{n=0}^\infty \frac{1}{n!}Q J^nQ^{-1} = Q\left(\sum_{n=0}^\infty \frac{1}{n!}J^n\right)Q^{-1} = Q e^J Q^{-1}.$$ So if we can find the matrix exponential of a matrix in Jordan form, and we can compute $Q$ and $Q^{-1}$, then we can find the matrix exponential of any matrix.  We will never go beyond 2 by 2 and 3 by 3 matrices when we do problems in class, but theoretically you now have the tools for computing matrix exponentials of any matrix.
If we need to find the matrix exponential of $At$, then we can find the matrix exponential of $Jt$ and get $exp(At)=Q\ exp(Jt)\ Q^{-1}$.  

As an example, let's consider the matrix 
$A=
\begin{bmatrix}
 2 & 1 \\
 1 & 2
\end{bmatrix}
$ whose eigenvalues are 1 and 3, with eigenvectors $[-1,1],[1,1]$.
We then have 
$Q=
\begin{bmatrix}
 -1 & 1 \\
 1 & 1
\end{bmatrix}
$ and 
$J=
\begin{bmatrix}
 1 & 0 \\
 0 & 3
\end{bmatrix}
$ 
so $exp(Jt) = 
\begin{bmatrix}
 e^{t} & 0 \\
 0 & e^{3t}
\end{bmatrix}
$ and the matrix exponential of $At$ is 
$$exp(At) = Q e^{Jt}Q^{-1} =
\begin{bmatrix}
 -1 & 1 \\
 1 & 1
\end{bmatrix}
\begin{bmatrix}
 e^{t} & 0 \\
 0 & e^{3t}
\end{bmatrix}
\left(-\frac{1}{2}\right)
\begin{bmatrix}
 1 & -1 \\
 -1 & -1
\end{bmatrix}
=
\left(-\frac{1}{2}\right)
\begin{bmatrix}
 -e^t-e^{3 t} & e^t-e^{3 t} \\
 e^t-e^{3 t} & -e^t-e^{3 t}
\end{bmatrix}
$$

For an example with a repeated eigenvalue, let's consider the matrix 
$A=
\begin{bmatrix}
 0 & 1 \\
 -9 & 6
\end{bmatrix}
$.  We can compute 
$Q=
\begin{bmatrix}
 1 & -\frac{1}{3} \\
 3 & 0
\end{bmatrix}
$
and
$J=
\begin{bmatrix}
 3 & 1 \\
 0 & 3
\end{bmatrix}
$. The matrix exponential of $Jt$ is 
$
\begin{bmatrix}
 e^{3 t} & e^{3 t} t \\
 0 & e^{3 t}
\end{bmatrix}
$. We then have
$$exp\left(A t\right) = exp\left(
\begin{bmatrix}
 0 & 1t \\
 -9t & 6t
\end{bmatrix}
\right)
=
\begin{bmatrix}
 1 & -\frac{1}{3} \\
 3 & 0
\end{bmatrix}
\begin{bmatrix}
 e^{3 t} & e^{3 t} t \\
 0 & e^{3 t}
\end{bmatrix}
\begin{bmatrix}
 0 & \frac{1}{3} \\
 -3 & 1
\end{bmatrix}
=
\begin{bmatrix}
 e^{3 t}-3 e^{3 t} t & e^{3 t} t \\
 -9 e^{3 t} t & 3 e^{3 t} t+e^{3 t}
\end{bmatrix}
.
$$

If the eigenvalues are irrational or complex, the computations are still the same. When the eigenvalues are complex, Euler's formula $e^{ix}=\cos x+i\sin x$ or the identities $\cosh ix = \cos x, \sinh ix = i\sin x$ can be used to simplify the matrix exponential so that it contains no imaginary components. We will focus only on examples where the eigenvalues are real, and leave the complex case to another class.


\section{Applications to Systems of ODEs}
\subsection{Dilution - Tank Mixing Problems}
Let's look at an application to see why systems of differential equations are useful. Systems are used to understand the motion of moving parts in a machine, the flow of electricity in a complex network, and many more places. Lets focus on a dilution problem with multiple tanks, so we can see how the systems of ODEs are created. We won't be solving any of the ODEs below by hand, rather we will just set them up and let the computer solve them by finding the matrix exponential.

Suppose that two tanks are connected via tubes so that the water in the tanks can circulate between each other.  Both tanks contain 50 gallons of water. The first tank contains 100lbs of salt, while the second tank is pure water.  The tubes connecting the tanks allow 3 gallons of water to flow from the first tank to the second tank each minute.  Similarly, 3 gallons of water are allowed to flow from tank 2 to tank 1 each minute. As soon as water enters either tank, a mixing blade ensures that the salt content is perfectly mixed into the tank.  The problem we want to solve is this: how much salt is in each tank at any given time $t$.  We know that after sufficient time, we should have 50lbs in each tank (since 100 lbs spread evenly between two tanks will give 50 lbs in each tank).

Let $y_1(t)$ be the salt content in lbs in tank 1, and $y_2(t)$ be the salt content in tank 2, where $t$ is given in minutes and $y_1$ and $y_2$ are given in lbs. We know that 3 gallons of water flows out of each tank each minute, and 3 gallons flows in each minute.  Let's focus on tank 1 for a minute and determine its outflow and inflow rates.  The only water coming into tank 1 each minute comes from tank 2.  We know that 3 out of the 50 gallons from tank 2 will enter tank 1, so the fraction $\frac{3}{50}$ represents the proportion of water leaving tank 2 and entering tank 1. This means that the inflow rate for tank 1 is $\frac{3}{50}y_2$.  Similarly, the outflow rate for tank 1 is $\frac{3}{50}y_2$.  Combining these gives a differential equation $y_1^\prime = \frac{3}{50}y_2 - \frac{3}{50}y_1$.  Examining tank 2 gives the equation $y_2^\prime = \frac{3}{50}y_1 - \frac{3}{50}y_2$.  We now have a system of ODEs 
$\begin{cases}
y_1^\prime = \frac{3}{50}y_2 - \frac{3}{50}y_1\\
y_2^\prime = \frac{3}{50}y_1 - \frac{3}{50}y_2
\end{cases}$ or in matrix form 
$
\begin{bmatrix}
y_1^\prime\\
y_2^\prime
\end{bmatrix}
=
\begin{bmatrix}
-3/50&3/50\\
3/50&-3/50
\end{bmatrix}
\begin{bmatrix}
y_1\\
y_2
\end{bmatrix}
+
\begin{bmatrix}
0\\
0
\end{bmatrix}$, which a first order homogeneous linear system of ODEs. The initial conditions are $y_1(0)=100$ and $y_2(0)=0$. A solution to this problem is $\vec y = e^{A t}\vec y(0)$.


Consider a similar problem, with these modifications.  Each tank still has 50 galls, with 100 lbs of salt in tank 1.  Each minute, 2 gallons of pure water are dumped into tank 1 from an outside source. The pump in tank 1 causes 5 gallons per minute to leave tank 1 and enter tank 2.  The pump in tank 2 cause only 3 gallons per minute to flow back into tank 1. The extra 2 gallons per minute which flow into tank 2 from the tank 1 pipes flow out of the system via a drainage pipe.  How much water is in each tank at any given time?

The flow into tank 1 comes from 2 parts. Each minute 2 gallons containing 0 lbs/gal enters the tank, so no salt enters.  In addition, 3/50 ths of the salt in tank 2 will enter tank 1.  The outflow is 5/50 ths the salt in tank 1, since 5 gal are flowing toward tank 2 each minute.  This gives the ODE $y_1^\prime = 8+3/50 y_2 - 5/50 y_1$.  The inflow in the second tank is 5/50 ths of $y_1$, and the outflow is 3/50 ths of $y_2$ toward tank 1 plus 2/50 ths of $y_2$ toward drainage.  This means we have $y_2^\prime = 5/50 y_1 -5/50 y_2$.  In matrix form we can write the system as 
$\begin{cases}
y_1^\prime = \frac{3}{50}y_2 - \frac{5}{50}y_1\\
y_2^\prime = \frac{5}{50}y_1 - \frac{5}{50}y_2
\end{cases}$ or in matrix form 
$
\begin{bmatrix}
y_1^\prime\\
y_2^\prime
\end{bmatrix}
=
\begin{bmatrix}
-5/50&3/50\\
5/50&-5/50
\end{bmatrix}
\begin{bmatrix}
y_1\\
y_2
\end{bmatrix}
$, which is a homogeneous linear system of ODEs, with initial conditions $y_1(0)=100$ and $y_2(0)=0$. 

Now let's change the size of the tanks, to see how size affects the problem.  Let tank 1 contain 100 gallons and tank 2 contain 50 gallons. Dump 3 gallons or pure water into tank 1 each minute.  Pumps cause 6 gallons to flow from tank 1 to tank 2, and 3 gallons to flow from tank 2 to tank 1.  This leaves 3 gallons per minute to leave via a drain pipe in tank 2. The corresponding system of ODEs would be $y_1^\prime = 3/50 y_2 - 6/100 y_1$ and $y_2^\prime = 6/100 y_1 - 6/50 y_2$. In matrix form we can write this as  
$
\begin{bmatrix}
y_1^\prime\\
y_2^\prime
\end{bmatrix}
=
\begin{bmatrix}
-6/100&3/50\\
6/100&-6/50
\end{bmatrix}
\begin{bmatrix}
y_1\\
y_2
\end{bmatrix}
$.
 
As a final example, let's consider 3 tanks.  Suppose tank 1 contains 100 gallons with 300 lbs of salt.  Tank 2 contains 50 gallons with 20 lbs of salt, and tank 3 contains 30 gallons of pure water.  Pumps allows 2 gallons per minute to flow each direction between tank 1 and tank 2.  Another set of pumps allows 3 gallons per minute to flow between tanks 1 and 3.  There are no pumps connecting tank 2 and tank 3. Let's set up a system of ODEs in matrix form whose solution would give us the salt content in each tank at any given time.  For tank 1, we have an inflow of 2/50 $y_2$ plus 3/40 $y_3$. The outflow is 5/100 $y_1$ (2 gal toward tank 2 and 3 toward tank 3).  Continuing in this fashion, we eventually obtain the matrix equation
$
\begin{bmatrix}
y_1^\prime\\
y_2^\prime\\
y_3^\prime
\end{bmatrix}
=
\begin{bmatrix}
-5/100&2/50 &3/40\\
2/100 &-2/50&0\\
3/100 &0    &-3/40
\end{bmatrix}
\begin{bmatrix}
y_1\\
y_2\\
y_3
\end{bmatrix}
$, which is a homogeneous linear first order system of ODEs.

Problems such as the ones above appear in waste processing plants, chemical labs, immigration, supply/demand, economics, and more. Learning how to set up and solve more complicated problems is the content of an introductory course in differential equations.  The point to this unit is to help you see that every one of these problems can be solved by finding the matrix exponential, which is just an application diagonalizing a matrix (picking a good basis for a linear transformation).


\subsection{Solving a system of ODEs}
I'll finish with one more example to remind us how to use the matrix exponential to solve the differential equations above.  Recall at the beginning of the unit that the solution to the ODE 
 $y^\prime =a y$ is $y=e^{at}c$. In terms of systems, we can solve the linear system of equations with constant coefficient matrix $A$ given by $\vec y^\prime =A \vec y$ using the solution
$\vec y=e^{At}\vec c.$ If the initial conditions are $\vec y(0)=\vec y_0$, then the constant vector $\vec c$ must equal the initial conditions.

Lets solve the system of ODEs given by  
$
\begin{bmatrix}
y_1^\prime\\
y_2^\prime
\end{bmatrix}
=
\begin{bmatrix}
3&1\\
0&3
\end{bmatrix}
\begin{bmatrix}
y_1\\
y_2
\end{bmatrix}
$. Since the coefficient matrix $A = \begin{bmatrix}
3&1\\
0&3
\end{bmatrix}
$ is already in Jordan form, we know the matrix exponential of $A$ times $t$ is 
$exp(At) = 
\begin{bmatrix}
e^{3t}&te^{3t}\\
0&e^{3t}
\end{bmatrix}
$.  Hence we have as a solution to our ODE 
$
\begin{bmatrix}
y_1\\
y_2
\end{bmatrix}
=
\begin{bmatrix}
e^{3t}&te^{3t}\\
0&e^{3t}
\end{bmatrix}
\begin{bmatrix}
c_1\\
c_2
\end{bmatrix}
=
\begin{bmatrix}
c_1e^{3t}+c_2te^{3t}\\
c_2e^{3t}
\end{bmatrix}$. Without using matrix form, a general solution would be $y_1=c_1e^{3t}+c_2te^{3t}, y_2=c_2e^{3t}$.  To check our solution, we compute $y_1^\prime = 3c_1e^{3t}+3c_2te^{3t}+c_2e^{3t}$ and $y_2^\prime = 3c_2e^{3t}$.  The system of ODEs requires that $y_1^\prime = 3y_1+y_2 = 3(c_1e^{3t}+c_2te^{3t})+(c_2e^{3t})$ (which is correct), and that $y_2^\prime = 3y_2 = 3(c_2e^{3t})$ (which is also correct). 

In the previous problem, let's add the initial conditions $y_1(0)=2$ and $y_2(0)=7$. Recall that $e^0=I$, so plugging in $t=0$ into our vector equation $\vec y = e^{At}\vec c$ means 
$
\begin{bmatrix}
y_1(0)\\
y_2(0)
\end{bmatrix}
=I
\begin{bmatrix}
c_1\\
c_2
\end{bmatrix}
$, or 
$
\begin{bmatrix}
2\\
7
\end{bmatrix}
=
\begin{bmatrix}
c_1\\
c_2
\end{bmatrix}
$. Hence the solution of our initial value problem is simply the matrix exponential times the initial conditions, i.e.
$
\begin{bmatrix}
y_1\\
y_2
\end{bmatrix}
=
\begin{bmatrix}
e^{3t}&te^{3t}\\
0&e^{3t}
\end{bmatrix}
\begin{bmatrix}
2\\
7
\end{bmatrix}
$.

This solution technique solves almost every differential equation you will encounter in an introductory differential equations class. In an introduction to ODEs, you will learn many additional applications to motion, springs, electrical networks, and more. Knowing linear algebra provides you with the language needed to see how solutions in high dimensions are really just extensions of solutions in 1 dimension.

\end{document}


